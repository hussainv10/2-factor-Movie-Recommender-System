{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": "#Movie Recommendation Engine, NLP and Exploratory Analysis.\n#Part 1: ALS on MovieLens Ratings Dataset to acquire recommendations based on ratings\n#Part 2: Aggregate movies comments into recommended movies from IMDb/Amazon Movie reviews dataset\n#Part 3: Sentiment Analysis on comments and sorting recommendations based on sentiment score"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": "#Part 1: ALS on MovieLens Ratings Dataset to acquire recommendations based on ratings\n\nimport os\nfrom pyspark import SparkContext\nsc = SparkContext()\n\nfilepath='gs://homework0bucket/datasets/ml-latest-small'\n\nsample_ratings = os.path.join(filepath, 'ml-latest-small', 'ratings.csv')\n\n#Converting CSV file with ratings into textfile and parsing into RDD\nsample_ratings_raw = sc.textFile(sample_ratings)\nsample_ratings_raw_header = sample_ratings_raw.take(1)[0]\n\nsample_ratings_data = sample_ratings_raw.filter(lambda line: line!=sample_ratings_raw_header).map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache()\n\n#Repeating above process  for CSV file with movie names and identifiers\n\nsample_movies = os.path.join(filepath, 'ml-latest-small', 'movies.csv')\n\nsample_movies_raw_data = sc.textFile(sample_movies)\nsample_movies_raw_data_header = sample_movies_raw_data.take(1)[0]\n\nsmall_movies_data = sample_movies_raw_data.filter(lambda line: line!=sample_movies_raw_data_header).map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1])).cache()\n"}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Using Rank 4 results in an  RMSE of 0.9080781059018078\nUsing Rank 8 results in an  RMSE of 0.9164629732715387\nUsing Rank 12 results in an  RMSE of 0.9176650314972615\nOptimal Rank is 4\nRMSE for testing data from smaple dataset is 0.9113780952339309\n"}], "source": "#Beginning setup for ALS Matrix Factorization Model\n\nTrainingRDD, ValidateRDD, TestRDD = sample_ratings_data.randomSplit([6, 2, 2], seed=0)\nvalidation_predictRDD = ValidateRDD.map(lambda x: (x[0], x[1]))\nprediction_testingRDD = TestRDD.map(lambda x: (x[0], x[1]))\n\n#Defining ALS parameters to find optimal rank with best RMSE score\n\nfrom pyspark.mllib.recommendation import ALS\nimport math\n\nseed = 5\niterations = 10\nreg_parameter = 0.1\nranks = [4, 8, 12]\nerrors = [0, 0, 0]\nerr = 0\ntolerance = 0.02\n\nmin_error = float('inf')\nbest_rank = -1\nbest_iteration = -1\nfor rank in ranks:\n    matrix_factorization_model = ALS.train(TrainingRDD, rank, seed=seed, iterations=iterations,\n                      lambda_=reg_parameter)\n    predicted_ratings = matrix_factorization_model.predictAll(validation_predictRDD).map(lambda r: ((r[0], r[1]), r[2]))\n    ratings_and_predictions = ValidateRDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predicted_ratings)\n    error = math.sqrt(ratings_and_predictions.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n    errors[err] = error\n    err += 1\n    print (\"Using Rank %s results in an  RMSE of %s\" % (rank, error))\n    if error < min_error:\n        min_error = error\n        best_rank = rank\n\nprint (\"Optimal Rank is %s\" % best_rank)\n\npredicted_ratings.take(3)\n\nratings_and_predictions.take(3)\n\n#Testing  the ALS Model\n\nmatrix_factorization_model = ALS.train(TrainingRDD, best_rank, seed=seed, iterations=iterations,\n                      lambda_=reg_parameter)\npredicted_ratings = matrix_factorization_model.predictAll(prediction_testingRDD).map(lambda r: ((r[0], r[1]), r[2]))\nratings_and_predictions = TestRDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predicted_ratings)\nerror = math.sqrt(ratings_and_predictions.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n    \nprint (\"RMSE for testing data from smaple dataset is %s\" % (error))"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "There are 27753444 recommendations in the complete dataset\n"}], "source": "#Now that we have the ALS model ready, we can proceed by loading the complete dataset to generate recommendations for user\n\nratings_file = os.path.join(filepath, 'ml-latest', 'ratings.csv')\nratings_raw_data = sc.textFile(ratings_file)\nratings_raw_data_header = ratings_raw_data.take(1)[0]\n\n# Parse\nratings_data = ratings_raw_data.filter(lambda line: line!=ratings_raw_data_header).map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache()\n    \nprint (\"There are %s recommendations in the complete dataset\" % (ratings_data.count()))"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "RMSE for testing the model with complete data is 0.8310675821411432\n"}], "source": "#Retraining model with the complete dataset\n\nTrainingRDD, TestRDD = ratings_data.randomSplit([7, 3], seed=0)\n\ncomplete_matrix_model = ALS.train(TrainingRDD, best_rank, seed=seed, iterations=iterations, lambda_=reg_parameter)\n\n#Testing it again\n\nprediction_testingRDD = TestRDD.map(lambda x: (x[0], x[1]))\n\npredicted_ratings = complete_matrix_model.predictAll(prediction_testingRDD).map(lambda r: ((r[0], r[1]), r[2]))\nratings_and_predictions = TestRDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predicted_ratings)\nerror = math.sqrt(ratings_and_predictions.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n    \nprint (\"RMSE for testing the model with complete data is %s\" % (error))\n\n#ALS Model is ready. Also note that using the compete data set with more reference points generates a better RMSE score"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Number of movies in dataset: 58098\n"}], "source": "#We can now start defining the engine using  the ALS model as the core\n\nmovies_file = os.path.join(filepath, 'ml-latest', 'movies.csv')\nmovies_raw_data = sc.textFile(movies_file)\nmovies_raw_data_header = movies_raw_data.take(1)[0]\n\n# Parse\nmovies_data = movies_raw_data.filter(lambda line: line!=movies_raw_data_header)\\\n    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),tokens[1],tokens[2])).cache()\n\nmovies_titles = movies_data.map(lambda x: (int(x[0]),x[1]))\n    \nprint (\"Number of movies in dataset: %s\" % (movies_titles.count()))\n\n#Counting number of ratings for a movie. Only movies with a certain number of recommendations will be used.\n\ndef rating_counter_and_avg(ID_and_ratings_tuple):\n    nratings = len(ID_and_ratings_tuple[1])\n    return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1]))/nratings)\n\nmovieID_ratings_RDD = (ratings_data.map(lambda x: (x[1], x[2])).groupByKey())\nmovieID_average_ratings_RDD = movieID_ratings_RDD.map(rating_counter_and_avg)\nratings_count_RDD = movieID_average_ratings_RDD.map(lambda x: (x[0], x[1][0]))\n\n#Engine is defined and ready to accept user inputs"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "New user ratings: [(0, 260, 9), (0, 1, 8), (0, 16, 7), (0, 25, 8), (0, 32, 9), (0, 335, 4), (0, 379, 3), (0, 296, 7), (0, 858, 10), (0, 50, 8)]\n"}], "source": "#adding new user manually to test engine. Front end API will accept inputs in finished model\n\nnew_user_ID = 0\n\n# The format of each line is (userID, movieID, rating)\nnew_user_ratings = [\n     (0,260,9), # Star Wars (1977)\n     (0,1,8), # Toy Story (1995)\n     (0,16,7), # Casino (1995)\n     (0,25,8), # Leaving Las Vegas (1995)\n     (0,32,9), # Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n     (0,335,4), # Flintstones, The (1994)\n     (0,379,3), # Timecop (1994)\n     (0,296,7), # Pulp Fiction (1994)\n     (0,858,10) , # Godfather, The (1972)\n     (0,50,8) # Usual Suspects, The (1995)\n    ]\nnew_user_ratings_RDD = sc.parallelize(new_user_ratings)\nprint (\"New user ratings: %s\" % new_user_ratings_RDD.take(10))\n\n#adding new user ratings to dataframe\ncomplete_data_with_new_ratings_RDD = ratings_data.union(new_user_ratings_RDD)\n\n#new user ratings have been added"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "New model trained in 252.227 seconds\nTOP recommended movies (with more than 25 reviews):\n('Connections (1978)', 9.589850272368153, 49)\n('Music for One Apartment and Six Drummers (2001)', 9.113976248583668, 31)\n('\"Lonely Wife', 9.044589041529733, 43)\n('Strangers in Good Company (1990)', 9.032467453870453, 26)\n('\"Human Condition III', 8.941111300670922, 91)\n('Harakiri (Seppuku) (1962)', 8.940563136081561, 679)\n('\"In the blue sea', 8.924261294747879, 37)\n('\"Dylan Moran: Yeah', 8.902586629245722, 81)\n('\"Hollow Crown', 8.863678371058903, 36)\n('Planet Earth (2006)', 8.853181667310956, 1384)\n(\"Won't You Be My Neighbor? (2018)\", 8.840681254090555, 83)\n('Blue Planet II (2017)', 8.838191985348487, 349)\n('Ikiru (1952)', 8.833728045119933, 1551)\n('Patton Oswalt: Werewolves and Lollipops (2007)', 8.832686105760956, 56)\n('Planet Earth II (2016)', 8.830913001011101, 853)\n('Duck Amuck (1953)', 8.83054122822869, 226)\n('\"Personal Journey with Martin Scorsese Through American Movies', 8.825504727300359, 44)\n('\"I', 8.815280443441466, 85)\n('Life (2009)', 8.814937033793207, 166)\n('\"Things I Like', 8.809800892971154, 30)\n('Alone in the Wilderness (2004)', 8.80133721096972, 343)\n('The Garden of Sinners - Chapter 5: Paradox Paradigm (2008)', 8.78985018399117, 27)\n('Eight Deadly Shots (Kahdeksan surmanluotia) (1972)', 8.788001764996945, 30)\n('\"Life of Oharu', 8.783473176280289, 52)\n('Over the Garden Wall (2013)', 8.777492358261764, 377)\n"}], "source": "#Generating recommendations for the new user\n\n#training the ALS matrix model core to identify user preferences\nfrom time import time\n\nt0 = time()\nnew_ratings_matrix_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed, \n                              iterations=iterations, lambda_=reg_parameter)\ntt = time() - t0\n\nprint (\"New model trained in %s seconds\" % round(tt,3))\n\n\nnew_user_ratings_ids = map(lambda x: x[1], new_user_ratings)\nnew_user_unrated_movies_RDD = (movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\nnew_user_recommendations_RDD = new_ratings_matrix_model.predictAll(new_user_unrated_movies_RDD)\n\n# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\nnew_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\nnew_user_recommendations_rating_title_and_count_RDD = \\\n    new_user_recommendations_rating_RDD.join(movies_titles).join(ratings_count_RDD)\nnew_user_recommendations_rating_title_and_count_RDD.take(3)\n\nnew_user_recommendations_rating_title_and_count_RDD = \\\n    new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))\n\n#filtering out movies with less than 25 ratings. This cell can also be used to filter recommendations based on genre and dates.\n\ntop_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=25).takeOrdered(25, key=lambda x: -x[1])\n\nprint ('TOP recommended movies (with more than 25 reviews):\\n%s' %\n        '\\n'.join(map(str, top_movies)))\n\n#End of part 1\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "#predicting user ratings for given user ID\n\n#my_movie = sc.parallelize([(0, 500)]) \n#individual_movie_rating_RDD = new_ratings_matrix_model.predictAll(new_user_unrated_movies_RDD)\n#individual_movie_rating_RDD.take(1)"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.5"}}, "nbformat": 4, "nbformat_minor": 2}